{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_files = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = np.zeros(\n",
    "            (list_of_files, 217, 174), dtype=np.float64\n",
    "        )\n",
    "labels = np.zeroes(\n",
    "    (list_of_files,3), dtype = np.float64\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 217, 174)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "del data_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_directory = 'music_3080_parsed_11.mp3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_features_into_data(waveform,data,labels,file_number,file_name):\n",
    "    mfcc = librosa.feature.mfcc(waveform,sr = 44100, n_mfcc = 15)\n",
    "    mel = librosa.feature.melspectrogram(waveform, sr = 44100)\n",
    "    cens = librosa.feature.chroma_cens(waveform, sr = 44100, n_chroma = 15)\n",
    "    ton = librosa.feature.tonnetz(waveform,sr = 44100, chroma = cens)\n",
    "    cqt = librosa.feature.chroma_cqt(waveform,sr = 44100, n_chroma = 5)\n",
    "    stft = librosa.feature.chroma_stft(waveform, sr = 44100, n_chroma = 5)\n",
    "    data[file_number,:,0:15] = mfcc.T\n",
    "    data[file_number,:,15:143] = mel.T\n",
    "    data[file_number,:,143:158] = cens.T\n",
    "    data[file_number,:,158:164] = ton.T\n",
    "    data[file_number,:,164:169] = cqt.T\n",
    "    data[file_number,:,169:174] = stft.T\n",
    "    label = file_name.split('_')[0]\n",
    "    for i in range(3):\n",
    "        labels[file_number][i] = label[i]\n",
    "    return data,labels\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_n = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = librosa.load(data_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = load_features_into_data(f[0],data_train,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(217, 174)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-40.32453537, 104.41842651,  -6.20430183,  41.90998077,\n",
       "       -25.0476799 , -13.0345459 ,  24.00344086,   4.51055908,\n",
       "        19.46505737,  17.90101814,  11.11997414,  16.29535675,\n",
       "       -14.38159561,   9.679636  ,  10.76276207,   0.        ,\n",
       "         0.        ,   0.        ,   0.        ,   0.        ,\n",
       "         0.        ,   0.        ,   0.        ,   0.        ,\n",
       "         0.        ,   0.        ,   0.        ,   0.        ,\n",
       "         0.        ,   0.        ,   0.        ,   0.        ,\n",
       "         0.        ,   0.        ,   0.        ,   0.        ,\n",
       "         0.        ,   0.        ,   0.        ,   0.        ,\n",
       "         0.        ,   0.        ,   0.        ,   0.        ,\n",
       "         0.        ,   0.        ,   0.        ,   0.        ,\n",
       "         0.        ,   0.        ,   0.        ,   0.        ,\n",
       "         0.        ,   0.        ,   0.        ,   0.        ,\n",
       "         0.        ,   0.        ,   0.        ,   0.        ,\n",
       "         0.        ,   0.        ,   0.        ,   0.        ,\n",
       "         0.        ,   0.        ,   0.        ,   0.        ,\n",
       "         0.        ,   0.        ,   0.        ,   0.        ,\n",
       "         0.        ,   0.        ,   0.        ,   0.        ,\n",
       "         0.        ,   0.        ,   0.        ,   0.        ,\n",
       "         0.        ,   0.        ,   0.        ,   0.        ,\n",
       "         0.        ,   0.        ,   0.        ,   0.        ,\n",
       "         0.        ,   0.        ,   0.        ,   0.        ,\n",
       "         0.        ,   0.        ,   0.        ,   0.        ,\n",
       "         0.        ,   0.        ,   0.        ,   0.        ,\n",
       "         0.        ,   0.        ,   0.        ,   0.        ,\n",
       "         0.        ,   0.        ,   0.        ,   0.        ,\n",
       "         0.        ,   0.        ,   0.        ,   0.        ,\n",
       "         0.        ,   0.        ,   0.        ,   0.        ,\n",
       "         0.        ,   0.        ,   0.        ,   0.        ,\n",
       "         0.        ,   0.        ,   0.        ,   0.        ,\n",
       "         0.        ,   0.        ,   0.        ,   0.        ,\n",
       "         0.        ,   0.        ,   0.        ,   0.        ,\n",
       "         0.        ,   0.        ,   0.        ,   0.        ,\n",
       "         0.        ,   0.        ,   0.        ,   0.        ,\n",
       "         0.        ,   0.        ,   0.        ,   0.        ,\n",
       "         0.        ,   0.        ,   0.        ,   0.        ,\n",
       "         0.        ,   0.        ,   0.        ,   0.        ,\n",
       "         0.        ,   0.        ,   0.        ,   0.        ,\n",
       "         0.        ,   0.        ,   0.        ,   0.        ,\n",
       "         0.        ,   0.        ,   0.        ,   0.        ,\n",
       "         0.        ,   0.        ,   0.        ,   0.        ,\n",
       "         0.        ,   0.        ,   0.        ,   0.        ,\n",
       "         0.        ,   0.        ])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train[0][50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-3.28942528e+01,  9.63850174e+01,  1.86830978e+01,  3.96652770e+00,\n",
       "        2.30371933e+01,  8.59519672e+00,  1.28909550e+01,  1.58068943e+01,\n",
       "       -1.22594681e+01,  4.18005228e-01,  8.16409492e+00,  2.60835037e+01,\n",
       "        2.60919094e+00,  5.23773670e+00, -2.76716089e+00,  1.34363266e+02,\n",
       "        1.82679840e+02,  3.51267761e+02,  2.43906372e+02,  8.57272110e+01,\n",
       "        5.25289726e+01,  1.56688719e+01,  1.20454493e+01,  5.75646305e+00,\n",
       "        1.13034592e+01,  5.87525558e+00,  6.01613760e+00,  1.47809803e+00,\n",
       "        7.61048841e+00,  4.58567619e+00,  1.68514729e+01,  5.26687670e+00,\n",
       "        9.90575695e+00,  3.93803430e+00,  7.45014286e+00,  2.33907771e+00,\n",
       "        6.19673967e+00,  4.86912346e+00,  8.71595669e+00,  4.98408222e+00,\n",
       "        3.34902859e+00,  1.13442385e+00,  1.49114823e+00,  3.28647107e-01,\n",
       "        1.38497150e+00,  9.20922816e-01,  3.76273298e+00,  9.49288666e-01,\n",
       "        9.99694228e-01,  1.43198645e+00,  1.05583191e+00,  6.21294677e-01,\n",
       "        1.20141017e+00,  8.66826236e-01,  4.63559091e-01,  1.01525855e+00,\n",
       "        1.78449106e+00,  2.20740581e+00,  5.43897200e+00,  8.77470303e+00,\n",
       "        8.43828583e+00,  5.53517342e+00,  3.87368226e+00,  6.15075636e+00,\n",
       "        3.60053396e+00,  2.98235941e+00,  1.07906747e+00,  5.35575926e-01,\n",
       "        6.59151137e-01,  3.12774152e-01,  3.24404746e-01,  7.48307526e-01,\n",
       "        2.36099660e-01,  2.01290071e-01,  1.14847459e-01,  5.15902154e-02,\n",
       "        1.57946929e-01,  1.77710086e-01,  2.24196777e-01,  4.87607062e-01,\n",
       "        9.28998590e-01,  8.06094766e-01,  1.08482146e+00,  5.69693208e-01,\n",
       "        1.79273397e-01,  1.93356231e-01,  3.96099061e-01,  8.17487001e-01,\n",
       "        7.54049778e-01,  5.83375335e-01,  2.84779996e-01,  1.88204437e-01,\n",
       "        2.43145511e-01,  2.50449985e-01,  1.59581855e-01,  1.07446961e-01,\n",
       "        1.31569088e-01,  2.64685035e-01,  2.76365072e-01,  1.35718375e-01,\n",
       "        6.48971647e-02,  1.82680134e-02,  1.90884490e-02,  5.39246686e-02,\n",
       "        2.88945381e-02,  4.08767164e-02,  5.28245270e-02,  3.39102596e-02,\n",
       "        4.67877463e-02,  4.29781750e-02,  4.14679348e-02,  6.54792637e-02,\n",
       "        9.44856629e-02,  5.69101237e-02,  2.76352633e-02,  1.24670276e-02,\n",
       "        2.50213500e-02,  5.76369278e-02,  1.87428705e-02,  2.05604769e-02,\n",
       "        3.22147682e-02,  5.27202561e-02,  3.64924930e-02,  3.42084989e-02,\n",
       "        1.07570171e-01,  1.33182779e-01,  8.15078169e-02,  3.81317213e-02,\n",
       "        6.62537143e-02,  3.32248479e-01,  2.59429276e-01,  2.59827584e-01,\n",
       "        3.10040712e-01,  9.32758525e-02,  6.47120923e-02,  7.25704283e-02,\n",
       "        7.79665038e-02,  1.09175347e-01,  7.72096142e-02,  4.30372655e-02,\n",
       "        5.39551750e-02,  6.18936941e-02,  3.80126247e-03,  1.22809121e-01,\n",
       "        1.40057528e-01,  6.66438918e-02,  5.90671286e-04,  4.58673420e-02,\n",
       "        1.85924870e-01,  4.67940252e-01,  6.97713475e-01,  4.67349581e-01,\n",
       "        1.18664411e-04,  0.00000000e+00,  0.00000000e+00,  5.90671286e-04,\n",
       "        1.18664411e-04,  0.00000000e+00, -3.95458953e-02,  2.92924025e-03,\n",
       "       -2.18533309e-02,  7.31740615e-02, -3.21173843e-02,  8.95107058e-02,\n",
       "        1.00000000e+00,  3.58411223e-01,  8.65370929e-01,  7.50236690e-01,\n",
       "        3.55282128e-01,  7.50028789e-01,  1.00000000e+00,  5.56728899e-01,\n",
       "        7.09902167e-01,  6.94449425e-01])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d[0][216]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, batch_size, output_dim=3, num_layers=2):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.batch_size = batch_size\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        # setup LSTM layer\n",
    "        self.lstm = nn.LSTM(self.input_dim, self.hidden_dim, self.num_layers)\n",
    "\n",
    "        # setup output layer\n",
    "        self.linear = nn.Linear(self.hidden_dim, output_dim)\n",
    "\n",
    "    def init_hidden(self):\n",
    "        return (\n",
    "            torch.zeros(self.num_layers, self.batch_size, self.hidden_dim),\n",
    "            torch.zeros(self.num_layers, self.batch_size, self.hidden_dim),\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        # lstm step => then ONLY take the sequence's final timetep to pass into the linear/dense layer\n",
    "        # Note: lstm_out contains outputs for every step of the sequence we are looping over (for BPTT)\n",
    "        # but we just need the output of the last step of the sequence, aka lstm_out[-1]\n",
    "        lstm_out, hidden = self.lstm(input)\n",
    "        logits = self.linear(lstm_out[-1])\n",
    "        genre_scores = F.log_softmax(logits, dim=1)\n",
    "        return genre_scores\n",
    "\n",
    "    def get_accuracy(self, logits, target):\n",
    "        \"\"\" compute accuracy for training round \"\"\"\n",
    "        corrects = (\n",
    "            torch.max(logits, 1)[1].view(target.size()).data == target.data\n",
    "        ).sum()\n",
    "        accuracy = 100.0 * corrects / self.batch_size\n",
    "        return accuracy.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build LSTM RNN model ...\n",
      "\n",
      "Training on GPU\n"
     ]
    }
   ],
   "source": [
    "batch_size = 35  # num of training examples per minibatch\n",
    "num_epochs = 400\n",
    "\n",
    "# Define model\n",
    "print(\"Build LSTM RNN model ...\")\n",
    "model = LSTM(\n",
    "    input_dim=174, hidden_dim=256, batch_size=batch_size, output_dim=3, num_layers=2\n",
    ")\n",
    "loss_function = nn.NLLLoss()  # expects ouputs from LogSoftmax\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "train_on_gpu = torch.cuda.is_available()\n",
    "if train_on_gpu:\n",
    "    print(\"\\nTraining on GPU\")\n",
    "else:\n",
    "    print(\"\\nNo GPU, training on CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTM(\n",
       "  (lstm): LSTM(174, 256, num_layers=2)\n",
       "  (linear): Linear(in_features=256, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Whole Directory with all labels\n",
    "#For each file, add it into data and labels array\n",
    "# Split into train, test\n",
    "# Convert them into torch tensors.\n",
    "# Run for each epoch, for each batch, the forward and backward pass and calculate loss and accuracy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
